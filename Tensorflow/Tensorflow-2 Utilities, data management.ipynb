{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know the basic of tensorflow and can create a model, or at least copy paste code from last notebook, then chose a optimizer,loss function and write/run the training step. We now want to study some utitites/extended libraries that extends this process.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we forgot in the basic tensorflow notebook was what to do after training a model. One would like to save the model so one can load it and work with it in another program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Keras model consists of multiple components:\n",
    "\n",
    "- An architecture, or configuration, which specifyies what layers the model contain, and how they're connected.\n",
    "- A set of weights values (the \"state of the model\").\n",
    "- An optimizer (defined by compiling the model).\n",
    "- A set of losses and metrics (defined by compiling the model or calling add_loss() or add_metric()).\n",
    "\n",
    "The Keras API makes it possible to save of these pieces to disk at once, or to only selectively save some of them:\n",
    "\n",
    "- Saving everything into a single archive in the TensorFlow SavedModel format (or in the older Keras H5 format). This is the standard practice.\n",
    "- Saving the architecture / configuration only, typically as a JSON file. (Will not look into atm)\n",
    "- Saving the weights values only. This is generally used when training the model. (Will not look into atm)\n",
    "\n",
    "Let's use or model from the last notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mnist_images, mnist_labels), _ = K.datasets.mnist.load_data()\n",
    "\n",
    "#Ignore this for now\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "  (tf.cast(mnist_images[...,tf.newaxis]/255, tf.float32),\n",
    "   tf.cast(mnist_labels,tf.int64)))\n",
    "\n",
    "\n",
    "dataset = dataset.shuffle(1000).batch(32)\n",
    "\n",
    "#Optimizer, and loss function (from keras)\n",
    "optimizer = K.optimizers.Adam()\n",
    "loss_object = K.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model = K.Sequential([\n",
    "  K.layers.Conv2D(16,[3,3], activation='relu',\n",
    "                         input_shape=(None, None, 1)),\n",
    "  K.layers.Conv2D(16,[3,3], activation='relu'),\n",
    "  K.layers.GlobalAveragePooling2D(),\n",
    "  K.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    logits = mnist_model(images, training=True)\n",
    "    \n",
    "    # Add asserts to check the shape of the output.\n",
    "    tf.debugging.assert_equal(logits.shape, (32, 10))\n",
    "    \n",
    "    loss_value = loss_object(labels, logits)\n",
    "\n",
    "  loss_history.append(loss_value.numpy().mean())\n",
    "  grads = tape.gradient(loss_value, mnist_model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(grads, mnist_model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 finished\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    for (batch, (images, labels)) in enumerate(dataset):\n",
    "      train_step(images, labels)\n",
    "    print ('Epoch {} finished'.format(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the whole model with: (this is Tensorflow Savemodel)\n",
    "- model.save(path+'name')\n",
    "- models.load_model(path+'name')\n",
    "\n",
    "This will create a folder named name and contains 3 folders \n",
    "- assets  \n",
    "- saved_model.pb  \n",
    "- variables\n",
    "\n",
    "The model architecture, and training configuration (including the optimizer, losses, and metrics) are stored in saved_model.pb, the rest in variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\jonathan\\pycharmprojects\\notebook\\venv\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From c:\\users\\jonathan\\pycharmprojects\\notebook\\venv\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: mnist_model\\assets\n"
     ]
    }
   ],
   "source": [
    "mnist_model.save('mnist_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is DE56-6F87\n",
      "\n",
      " Directory of C:\\Users\\Jonathan\\PycharmProjects\\ML-notebook\\Tensorflow\\mnist_model\n",
      "\n",
      "2020-08-29  20:36    <DIR>          .\n",
      "2020-08-29  20:36    <DIR>          ..\n",
      "2020-08-29  20:36    <DIR>          assets\n",
      "2020-08-29  20:36            73ÿ090 saved_model.pb\n",
      "2020-08-29  20:36    <DIR>          variables\n",
      "               1 File(s)         73ÿ090 bytes\n",
      "               4 Dir(s)  18ÿ282ÿ639ÿ360 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls mnist_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
