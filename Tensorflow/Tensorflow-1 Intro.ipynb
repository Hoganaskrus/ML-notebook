{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting, the most confusing part about writing this (not \"most-most\" but quite confusing) was the choice between using keras and tensorflow. My first thought was that keras was tensorflows backend since it's a subpackage in tf i.e tf.keras. Since I heard about keras and used it since I thought it would be best to learn some of the backend but that was not the case.\n",
    "\n",
    "Tensorflow is the default backend for keras, since keras works as a ML API, but tensorflow and keras has grown together so when learning tensorflow one implicitly learns keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as K #don't realy like this reference but are commonly used\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow uses as expected tensors, the differs from numpy tensors by 2 things.\n",
    "\n",
    "1. They can be accelerated in the GPU/TPU.\n",
    "2. They are immutable, i.e can't be \"changed\". only create a new one.\n",
    "\n",
    "So let's study a tensor and define a 2x2 matrix, both from tensorflow but also as numpy/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "m1 = [[1.0, 2.0], \n",
    "      [3.0, 4.0]]\n",
    "\n",
    "m2 = np.array([[1.0, 2.0], \n",
    "               [3.0, 4.0]], dtype=np.float32)\n",
    "\n",
    "m3 = tf.constant([[1.0, 2.0], \n",
    "                  [3.0, 4.0]])\n",
    "\n",
    "print(type(m1))\n",
    "print(type(m2))\n",
    "print(type(m3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(m3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tf tensor has a shape and datatype and can easily be casted to a numpy array. The axes of the shape are usually ordered from global to local. (This way features vectors are contiguous in the memory) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Pictures/test.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(type(m3.numpy()))\n",
    "print(m3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also go the other way by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.constant(m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "x = 1\n",
    "y = 2\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected let's see how tensorflow does this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tfx = tf.constant(1)\n",
    "tfy = tf.constant(2)\n",
    "print(tfx+tfy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as with numpy it uses operator overloading, i.e element-wise operation or (@-matrix multiplication) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow also are able to represent ragged tensor and sparse tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[0, 1, 2, 3], [4, 5], [6, 7, 8], [9]]>\n"
     ]
    }
   ],
   "source": [
    "ragged_list = [\n",
    "    [0, 1, 2, 3],\n",
    "    [4, 5],\n",
    "    [6, 7, 8],\n",
    "    [9]]\n",
    "\n",
    "ragged_tensor = tf.ragged.constant(ragged_list)\n",
    "print(ragged_tensor)\n",
    "print(ragged_tensor.appendshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([1 2], shape=(2,), dtype=int32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],\n",
    "                                       values=[1, 2],\n",
    "                                       dense_shape=[3, 4])\n",
    "print(sparse_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have studied some constant tensors, that cannot change its value, so what happends if we want it to dynamically change something, or let it depend on something else (i.e a variable). The answer is tf.Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=\n",
      "array([[1, 2],\n",
      "       [3, 4]])>\n",
      "tf.Tensor([1 1], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "tf_variable = tf.Variable(np.array([[1,2],[3,4]]))\n",
    "print(tf_variable)\n",
    "\n",
    "print(tf.argmax(tf_variable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 2) dtype=int32, numpy=\n",
       "array([[4, 3],\n",
       "       [2, 1]])>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_variable.assign([[4,3],[2,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.Variable instance have the same lifecycle as other Python objects. When there are no references to a variable it is automatically deallocated, Variables can also be named which can help you track and debug them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable '1-D:0' shape=(2,) dtype=int32, numpy=array([1, 2])>\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(np.array([1,2]), name=\"1-D\")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow automatically choses where the tensors will be places. We can explicitly define them like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('CPU:0'):\n",
    "\n",
    "  # Create some tensors\n",
    "  a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "  c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are well behave and can be used over processor, but will cause an delay since it has to copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.  4.  9.]\n",
      " [ 4. 10. 18.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('CPU:0'):\n",
    "  a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "  b = tf.Variable([[1.0, 2.0, 3.0]])\n",
    "\n",
    "with tf.device('GPU:0'):\n",
    "  # Element-wise multiply\n",
    "  k = a * b\n",
    "\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow 2.0 presented eager execution, that has been up to now used freely. Before one had to define a Session and functions to be able to calculate the $a*b$ as above. More importantly it \"replaces\" the graph/session mode, that still exist, that was used to export it to different language and machine. Tensorflow 1.x graph has good distibuted training, performance optimzation, to bride the gap tensorflow implemented tf.function, which we will look at later.\n",
    "\n",
    "With that said, eager execution suits us good for now. With eager execution, eager training comes. We can use tf.GradientTape to trace operation for upcoming gradients, this uses the famous automatic differentiation, which is besicaly chain rule on steroids.\n",
    "\n",
    "This gradient tape \"records\" all the forward pass operation and plays the record backwards then discard it after the call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[2.]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable([[1.0]])\n",
    "with tf.GradientTape() as tape:\n",
    "  forward = w ** 2\n",
    "\n",
    "grad = tape.gradient(forward, w)\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It wouldn't (it would) be a gradient if it only could differentiate w.r.p one variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.1533583 -0.6595056]\n",
      " [ 2.3067167 -1.3190112]\n",
      " [ 3.460075  -1.9785168]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(tf.random.normal((3, 2)), name='w')\n",
    "b = tf.Variable(tf.zeros(2, dtype=tf.float32), name='b')\n",
    "x = [[1., 2., 3.]]\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "  y = x @ w + b\n",
    "  loss = tf.reduce_mean(y**2)\n",
    "\n",
    "[dl_dw, dl_db] = tape.gradient(loss, [w,b])\n",
    "print(dl_dw)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not everything will be auto differentiated, we need to have a variable to be able to derivate it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.0, shape=(), dtype=float32)\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['x0:0']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x0 = tf.Variable(3.0, name='x0') # Only one who will be watched from the point of the tape.\n",
    "\n",
    "x1 = tf.Variable(3.0, name='x1', trainable=False)\n",
    "\n",
    "x2 = tf.Variable(2.0, name='x2') + 1.0\n",
    "\n",
    "x3 = tf.constant(3.0, name='x3')\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  y = (x0**2) + (x1**2) + (x2**2)\n",
    "\n",
    "grad = tape.gradient(y, [x0, x1, x2, x3])\n",
    "\n",
    "for g in grad:\n",
    "  print(g)\n",
    "\n",
    "[var.name for var in tape.watched_variables()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(3.0)\n",
    "with tf.GradientTape() as tape:\n",
    "  tape.watch(x)\n",
    "  y = x**2\n",
    "\n",
    "# dy = 2x * dx\n",
    "dy_dx = tape.gradient(y, x)\n",
    "print(dy_dx.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometime one want to treat something as differentiable, we can use tape.watch() function to request the gradient of the intermidiate value. We can also control the flow, with usual python operation and also force the tape to compute gradients over the same computation i.e not throw it away when used (as it usually does)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(1.0)\n",
    "\n",
    "v0 = tf.Variable(2.0)\n",
    "v1 = tf.Variable(2.0)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "  tape.watch(x)\n",
    "  if x > 0.0:\n",
    "    result = v0\n",
    "  else:\n",
    "    result = v1**2 \n",
    "\n",
    "dv0, dv1 = tape.gradient(result, [v0, v1])\n",
    "\n",
    "print(dv0)\n",
    "print(dv1)\n",
    "\n",
    "del tape  # Drop the reference to the tape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient can sometime be None, and be hard to debug. Often when a target is not connected i.e df_dx = None when there is no x in f. A tricky problem is when we are not using assing on the variable or when we did calculation outside of tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#1. Replaced a variable with a tensor.\n",
    "\n",
    "x = tf.Variable(2.0)\n",
    "\n",
    "for epoch in range(2):\n",
    "  with tf.GradientTape() as tape:\n",
    "    y = x+1\n",
    "\n",
    "  print(tape.gradient(y, x))\n",
    "  x = x + 1   # This should be `x.assign_add(1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#2. Did calculations outside of TensorFlow\n",
    "x = tf.Variable([[1.0, 2.0],\n",
    "                 [3.0, 4.0]], dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  x2 = x**2\n",
    "\n",
    "  # This step is calculated with NumPy\n",
    "  y = np.mean(x2, axis=0)\n",
    "\n",
    "  # Like most ops, reduce_mean will cast the NumPy array to a constant tensor\n",
    "  # using `tf.convert_to_tensor`.\n",
    "  y = tf.reduce_mean(y, axis=0)\n",
    "\n",
    "print(tape.gradient(y, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the target tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#3. Did gradient not on a float\n",
    "\n",
    "# The x0 variable has an `int` dtype.\n",
    "x = tf.Variable([[2, 2],\n",
    "                 [2, 2]])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  # The path to x1 is blocked by the `int` dtype here.\n",
    "  y = tf.cast(x, tf.float32)\n",
    "  y = tf.reduce_sum(x)\n",
    "\n",
    "print(tape.gradient(y, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#4. Took gradients through a stateful object, i.e variable has an internal state (the value), the gradient stop there i.e does not go back to x0\n",
    "\n",
    "x0 = tf.Variable(3.0)\n",
    "x1 = tf.Variable(0.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  # Update x1 = x1 + x0.\n",
    "  x1.assign_add(x0)\n",
    "  # The tape starts recording from x1.\n",
    "  y = x1**2   # y = (x1 + x0)**2\n",
    "\n",
    "# This doesn't work.\n",
    "print(tape.gradient(y, x0))   #dy/dx0 = 2*(x1 + x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now now how to make variable and how to differentiate them. It's not that far from being able to do a ML model. We will go through the most used data set (do not quote me on that), we will use layers already defined but is besically some smart operation and layering on what we already seen (i.e variable and operations). We will also use a know optimizer and a loss function.\n",
    "\n",
    "Let's download the MNIST handwritten digits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mnist_images, mnist_labels), _ = K.datasets.mnist.load_data()\n",
    "\n",
    "#Ignore this for now\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "  (tf.cast(mnist_images[...,tf.newaxis]/255, tf.float32),\n",
    "   tf.cast(mnist_labels,tf.int64)))\n",
    "\n",
    "\n",
    "dataset = dataset.shuffle(1000).batch(32)\n",
    "\n",
    "#Optimizer, and loss function (from keras)\n",
    "optimizer = K.optimizers.Adam()\n",
    "loss_object = K.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a standard simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard CNN (from keras) a bunch of layers stacked\n",
    "mnist_model = K.Sequential([\n",
    "  tf.keras.layers.Conv2D(16,[3,3], activation='relu',\n",
    "                         input_shape=(None, None, 1)),\n",
    "  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have the forward pass and record it in our train_step function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    logits = mnist_model(images, training=True)\n",
    "    \n",
    "    # Add asserts to check the shape of the output.\n",
    "    tf.debugging.assert_equal(logits.shape, (32, 10))\n",
    "    \n",
    "    loss_value = loss_object(labels, logits)\n",
    "\n",
    "  loss_history.append(loss_value.numpy().mean())\n",
    "  grads = tape.gradient(loss_value, mnist_model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(grads, mnist_model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.3009412, shape=(), dtype=float32)\n",
      "tf.Tensor(2.304256, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3018851, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3039572, shape=(), dtype=float32)\n",
      "tf.Tensor(2.297106, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2997394, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3016849, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2918544, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3066485, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2943168, shape=(), dtype=float32)\n",
      "tf.Tensor(2.304329, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3100405, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3035934, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2997718, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2972698, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2946794, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2999954, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2968154, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3022866, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2996316, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3058028, shape=(), dtype=float32)\n",
      "tf.Tensor(2.30086, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2994556, shape=(), dtype=float32)\n",
      "tf.Tensor(2.296267, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2945757, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2982683, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2912903, shape=(), dtype=float32)\n",
      "tf.Tensor(2.294252, shape=(), dtype=float32)\n",
      "tf.Tensor(2.30252, shape=(), dtype=float32)\n",
      "tf.Tensor(2.293088, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3059514, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2945566, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3019044, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2925017, shape=(), dtype=float32)\n",
      "tf.Tensor(2.294114, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3029811, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3047943, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2884011, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2844467, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2816374, shape=(), dtype=float32)\n",
      "tf.Tensor(2.29821, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3069386, shape=(), dtype=float32)\n",
      "tf.Tensor(2.29742, shape=(), dtype=float32)\n",
      "tf.Tensor(2.284059, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2856805, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2977638, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2908068, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2807713, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2964268, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2901778, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3016362, shape=(), dtype=float32)\n",
      "tf.Tensor(2.307064, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2927823, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2740457, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3130376, shape=(), dtype=float32)\n",
      "tf.Tensor(2.284869, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2811427, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2730517, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3039107, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2703915, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2831683, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2646236, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2850647, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2841198, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2940245, shape=(), dtype=float32)\n",
      "tf.Tensor(2.294559, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2766778, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2896183, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2580664, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2932363, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2985055, shape=(), dtype=float32)\n",
      "tf.Tensor(2.269353, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2401142, shape=(), dtype=float32)\n",
      "tf.Tensor(2.272996, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2671375, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2940454, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3049755, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2842212, shape=(), dtype=float32)\n",
      "tf.Tensor(2.28433, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2790344, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2742243, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3038774, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2990465, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2839966, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3382163, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2937474, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2453136, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2550054, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2541623, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2922263, shape=(), dtype=float32)\n",
      "tf.Tensor(2.312282, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2784038, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2838035, shape=(), dtype=float32)\n",
      "tf.Tensor(2.290855, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2599525, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2879152, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3061874, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2664304, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2649693, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3023024, shape=(), dtype=float32)\n",
      "tf.Tensor(2.286913, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2817168, shape=(), dtype=float32)\n",
      "tf.Tensor(2.255081, shape=(), dtype=float32)\n",
      "tf.Tensor(2.285506, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2714024, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3152242, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2807312, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2792745, shape=(), dtype=float32)\n",
      "tf.Tensor(2.272219, shape=(), dtype=float32)\n",
      "tf.Tensor(2.269609, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2606707, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2628117, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2709255, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2787142, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2658653, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2599962, shape=(), dtype=float32)\n",
      "tf.Tensor(2.29971, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2623348, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2580504, shape=(), dtype=float32)\n",
      "tf.Tensor(2.266306, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2797718, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2526016, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2306604, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2825804, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2706742, shape=(), dtype=float32)\n",
      "tf.Tensor(2.280931, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2671409, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2837038, shape=(), dtype=float32)\n",
      "tf.Tensor(2.280704, shape=(), dtype=float32)\n",
      "tf.Tensor(2.288867, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2435308, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2303782, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2816753, shape=(), dtype=float32)\n",
      "tf.Tensor(2.267356, shape=(), dtype=float32)\n",
      "tf.Tensor(2.230487, shape=(), dtype=float32)\n",
      "tf.Tensor(2.247982, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2738435, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2497957, shape=(), dtype=float32)\n",
      "tf.Tensor(2.243628, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1879418, shape=(), dtype=float32)\n",
      "tf.Tensor(2.26355, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2205827, shape=(), dtype=float32)\n",
      "tf.Tensor(2.21238, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2698762, shape=(), dtype=float32)\n",
      "tf.Tensor(2.249701, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1711488, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2714741, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2499738, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1856818, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2353296, shape=(), dtype=float32)\n",
      "tf.Tensor(2.28812, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2323647, shape=(), dtype=float32)\n",
      "tf.Tensor(2.29181, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2878652, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2443845, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2680502, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2610116, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2825513, shape=(), dtype=float32)\n",
      "tf.Tensor(2.244484, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2343519, shape=(), dtype=float32)\n",
      "tf.Tensor(2.21906, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2357297, shape=(), dtype=float32)\n",
      "tf.Tensor(2.194501, shape=(), dtype=float32)\n",
      "tf.Tensor(2.29487, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2496076, shape=(), dtype=float32)\n",
      "tf.Tensor(2.221817, shape=(), dtype=float32)\n",
      "tf.Tensor(2.263639, shape=(), dtype=float32)\n",
      "tf.Tensor(2.250225, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2271242, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2406816, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2494912, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2724233, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2246695, shape=(), dtype=float32)\n",
      "tf.Tensor(2.250942, shape=(), dtype=float32)\n",
      "tf.Tensor(2.211784, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2615457, shape=(), dtype=float32)\n",
      "tf.Tensor(2.228778, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2459934, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2112908, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2651877, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2193503, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.256456, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2728596, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2362113, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2322571, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2160006, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2324033, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1951957, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2076073, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2063093, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2162795, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1668935, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2461364, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2203891, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2203834, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2012486, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2096026, shape=(), dtype=float32)\n",
      "tf.Tensor(2.196995, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2413652, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2204132, shape=(), dtype=float32)\n",
      "tf.Tensor(2.255425, shape=(), dtype=float32)\n",
      "tf.Tensor(2.190711, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1818318, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2494857, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2199519, shape=(), dtype=float32)\n",
      "tf.Tensor(2.232905, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2516441, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2395885, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1943517, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1932015, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1980882, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2067857, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2243772, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1971116, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1828313, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1726346, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2314696, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1840758, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2159717, shape=(), dtype=f"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 10000 exceeded with 10191 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f46e3793ce42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m       \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch {} finished'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-a60e1d027d43>\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(images, labels)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Add asserts to check the shape of the output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jonathan\\pycharmprojects\\notebook\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jonathan\\pycharmprojects\\notebook\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    370\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[1;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jonathan\\pycharmprojects\\notebook\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    384\u001b[0m     \"\"\"\n\u001b[0;32m    385\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m--> 386\u001b[1;33m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jonathan\\pycharmprojects\\notebook\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jonathan\\pycharmprojects\\notebook\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jonathan\\pycharmprojects\\notebook\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m           outputs = nn.bias_add(\n\u001b[1;32m--> 266\u001b[1;33m               outputs, self.bias, data_format=self._tf_data_format)\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jonathan\\pycharmprojects\\notebook\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jonathan\\pycharmprojects\\notebook\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n\u001b[0;32m   3365\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3366\u001b[0m       return gen_nn_ops.bias_add(\n\u001b[1;32m-> 3367\u001b[1;33m           value, bias, data_format=data_format, name=name)\n\u001b[0m\u001b[0;32m   3368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jonathan\\pycharmprojects\\notebook\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n\u001b[0;32m    676\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m    677\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"BiasAdd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         tld.op_callbacks, value, bias, \"data_format\", data_format)\n\u001b[0m\u001b[0;32m    679\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    for (batch, (images, labels)) in enumerate(dataset):\n",
    "      train_step(images, labels)\n",
    "    print ('Epoch {} finished'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss [entropy]')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('Batch #')\n",
    "plt.ylabel('Loss [entropy]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(False, shape=(), dtype=bool)\n",
      "tf.Tensor(False, shape=(), dtype=bool)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(False, shape=(), dtype=bool)\n",
      "tf.Tensor(False, shape=(), dtype=bool)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(False, shape=(), dtype=bool)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(False, shape=(), dtype=bool)\n",
      "tf.Tensor(False, shape=(), dtype=bool)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(False, shape=(), dtype=bool)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(False, shape=(), dtype=bool)\n",
      "tf.Tensor(False, shape=(), dtype=bool)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(True, shape=(), dtype=bool)\n",
      "tf.Tensor(False, shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "mnist_example = dataset.take(1)\n",
    "for image,labels in mnist_example.as_numpy_iterator():\n",
    "    p = tf.argmax(mnist_model.predict(image),axis=1)\n",
    "    for i,w in enumerate(p):\n",
    "        print(w==labels[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
